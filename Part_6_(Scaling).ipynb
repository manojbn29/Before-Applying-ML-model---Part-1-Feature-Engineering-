{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "killing-lending",
   "metadata": {},
   "source": [
    "# Feature Engineering - Scaling\n",
    "\n",
    "* To bring all features to smae scale we apply scalinh techniques\n",
    "* First do train test split and again apply scaling techniques to avoid overfitting\n",
    "* Some ml models we should not apply sacling techniques (eg : Decesion Trees, Random forest, XgBoost..etc)\n",
    "* Types of scalig techniques are \n",
    "\n",
    "1) Normalization (Min - Max scaler)\n",
    "\n",
    "2) Standardization\n",
    "\n",
    "3) Robust scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-nation",
   "metadata": {},
   "source": [
    "<img src=\"scaling image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-surgery",
   "metadata": {},
   "source": [
    "#### **Note: Whether to apply scaling or transformation for all ml models**\n",
    "Ans : NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "small-architecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "material-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y ,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "radical-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### interview question (do the train test split without importing the sk learn liberay or any modules)\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "import random\n",
    "\n",
    "index_array = list(range(len(df)))\n",
    "random.shuffle(index_array)\n",
    "\n",
    "import math\n",
    "train_index = index_array[:math.ceil(len(index_array) * 0.8)]\n",
    "test_index = index_array[math.ceil(len(index_array) * 0.2 ) : ]\n",
    "\n",
    "train_data = df.iloc[train_index, :]\n",
    "test_data = df.iloc[test_index, :]\n",
    "\n",
    "# to get input features\n",
    "X_train_data = train_data.iloc[:, :-1]\n",
    "X_test_data = test_data.iloc[:, :-1]\n",
    "\n",
    "# to get target \n",
    "y_train_data = train_data.iloc[:, :-1]\n",
    "y_test_data = test_data.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-draft",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1) Normalization (Min - Max scaler)\n",
    "\n",
    "* Normalization (or min-max normalization) scales all values in a fixed range between 0 and 1\n",
    "\n",
    "* Before normalization, it is always good practice to handle the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-lucas",
   "metadata": {},
   "source": [
    "<img src=\"minmax scaling image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-algorithm",
   "metadata": {},
   "source": [
    "##### manual approach\n",
    "\n",
    "df['normalized_col_name'] = (df['col_name'] - df['col_name'].min()) / (df['col_name'].max() - df['col_name'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sweet-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using sklearn pakage\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-librarian",
   "metadata": {},
   "source": [
    "## 2) Standardization\n",
    "\n",
    "* Standardization (or z-score normalization) scales the values while taking into account standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-riverside",
   "metadata": {},
   "source": [
    "<img src=\"standardization image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-physiology",
   "metadata": {},
   "source": [
    "mean is shown as μ and the standard deviation is shown as σ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-princeton",
   "metadata": {},
   "source": [
    "##### manual approach\n",
    "\n",
    "df['normalized_col_name'] = (df['col_name'] - df['col_name'].meam()) / (df['col_name'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "shared-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using sklearn pakage\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-conspiracy",
   "metadata": {},
   "source": [
    "## 3) Robust scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-little",
   "metadata": {},
   "source": [
    "<img src=\"robust scaling image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-democrat",
   "metadata": {},
   "source": [
    "Q1 is the 1st quartile (25th quantile) and Q3 is 3rd quartile (75th quantile)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-candy",
   "metadata": {},
   "source": [
    "##### manual approach\n",
    "\n",
    "df['normalized_col_name'] = (df['col_name'] - df['col_name'].quantile(0.25)) / (df['col_name'].quantile(0.75) - df['col_name'].quantile(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interim-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
